{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOHwUr7pwCJB"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3213,
     "status": "ok",
     "timestamp": 1575860998085,
     "user": {
      "displayName": "김성연",
      "photoUrl": "",
      "userId": "11703282769554310998"
     },
     "user_tz": -540
    },
    "id": "KCTCqdNmwCJI",
    "outputId": "18b8f26e-6296-47b4-d15d-3e32a094a726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27125,
     "status": "ok",
     "timestamp": 1575861022021,
     "user": {
      "displayName": "김성연",
      "photoUrl": "",
      "userId": "11703282769554310998"
     },
     "user_tz": -540
    },
    "id": "gEOvxVk9wwdR",
    "outputId": "8f92a383-3641-4507-ffd3-e6c3c4e61d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huK8QKI7wCJM"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "random_seed = 10\n",
    "num_epochs = 280\n",
    "initial_lr = 1e-3\n",
    "checkpoint_dir = \"/content/gdrive/My Drive/Colab_Notebooks/best-artworks-of-all-time/data/\" #FIXME\n",
    "\n",
    "log_interval = 20\n",
    "checkpoint_interval = 210\n",
    "\n",
    "running_option = \"test\"  \n",
    "#running_option = \"training\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9-D3H9ywCJP"
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(x)))\n",
    "        out = self.in2(self.conv2(out))\n",
    "        out = out + residual\n",
    "        return out    \n",
    "\n",
    "\n",
    "class UpsampleConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "class AutoencoderNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderNet, self).__init__()\n",
    "        # Initial convolution layers\n",
    "        self.encoder = nn.Sequential()\n",
    "        \n",
    "        self.encoder.add_module('conv1', ConvLayer(3, 32, kernel_size=9, stride=1))\n",
    "        self.encoder.add_module('in1', nn.InstanceNorm2d(32, affine=True))\n",
    "        self.encoder.add_module('relu1', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool1', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.encoder.add_module('conv2', ConvLayer(32, 64, kernel_size=3, stride=2))\n",
    "        self.encoder.add_module('in2', nn.InstanceNorm2d(64, affine=True))\n",
    "        self.encoder.add_module('relu2', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool2', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.encoder.add_module('conv3', ConvLayer(64, 128, kernel_size=3, stride=2))\n",
    "        self.encoder.add_module('in3', nn.InstanceNorm2d(128, affine=True))\n",
    "        self.encoder.add_module('relu3', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool3', nn.MaxPool2d(2,2))\n",
    "\n",
    "        # Residual layers\n",
    "        self.residual = nn.Sequential()\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.residual.add_module('resblock_%d' %(i+1), ResidualBlock(128))\n",
    "        \n",
    "        # Upsampling Layers\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.add_module('upsample1', nn.Upsample(scale_factor=2))\n",
    "        self.decoder.add_module('deconv1', UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2))\n",
    "        self.decoder.add_module('in4', nn.InstanceNorm2d(64, affine=True))\n",
    "        self.decoder.add_module('relu4', nn.ReLU())\n",
    "\n",
    "        self.decoder.add_module('upsample2', nn.Upsample(scale_factor=2))\n",
    "        self.decoder.add_module('deconv2', UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2))\n",
    "        self.decoder.add_module('in5', nn.InstanceNorm2d(32, affine=True))\n",
    "        self.decoder.add_module('relu5', nn.ReLU())\n",
    "\n",
    "        self.decoder.add_module('upsample3', nn.Upsample(scale_factor=2))\n",
    "        self.decoder.add_module('deconv3', ConvLayer(32, 3, kernel_size=9, stride=1))\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoder_output = self.encoder(X)\n",
    "        residual_output = self.residual(encoder_output)\n",
    "        decoder_output = self.decoder(residual_output)\n",
    "        return decoder_output\n",
    "\n",
    "    \n",
    "class ClassifierNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierNet, self).__init__()\n",
    "        # Initial convolution layers\n",
    "        self.encoder = nn.Sequential()\n",
    "        \n",
    "        self.encoder.add_module('conv1', ConvLayer(3, 32, kernel_size=9, stride=1))\n",
    "        self.encoder.add_module('in1', nn.InstanceNorm2d(32, affine=True))\n",
    "        self.encoder.add_module('relu1', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool1', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.encoder.add_module('conv2', ConvLayer(32, 64, kernel_size=3, stride=2))\n",
    "        self.encoder.add_module('in2', nn.InstanceNorm2d(64, affine=True))\n",
    "        self.encoder.add_module('relu2', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool2', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.encoder.add_module('conv3', ConvLayer(64, 128, kernel_size=3, stride=2))\n",
    "        self.encoder.add_module('in3', nn.InstanceNorm2d(128, affine=True))\n",
    "        self.encoder.add_module('relu3', nn.ReLU())\n",
    "        self.encoder.add_module('maxpool3', nn.MaxPool2d(2,2))\n",
    "\n",
    "        # Residual layers\n",
    "        self.residual = nn.Sequential()\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.residual.add_module('resblock_%d' %(i+1), ResidualBlock(128))\n",
    "        \n",
    "        #Classifier\n",
    "        self.fc = nn.Sequential()\n",
    "        \n",
    "        self.fc.add_module('fullyconnected1', nn.Linear(128*8*8, 1024))\n",
    "        self.fc.add_module('bn1', nn.BatchNorm1d(1024))\n",
    "        self.fc.add_module('relu4', nn.ReLU())\n",
    "        self.fc.add_module('fullyconnected2', nn.Linear(1024, 500))\n",
    "        self.fc.add_module('bc2', nn.BatchNorm1d(500))\n",
    "        self.fc.add_module('relu5', nn.ReLU())\n",
    "        self.fc.add_module('fullyconnected3', nn.Linear(500, 50))\n",
    "        #self.fc.add_module('softmax1', nn.Softmax(dim = 1)) \n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoder_output = self.encoder(X)\n",
    "        residual_output = self.residual(encoder_output) #autoencoder\n",
    "        residual_flatten = residual_output.view(residual_output.size(0), -1)        \n",
    "        classifier_output = self.fc(residual_flatten) #classifier\n",
    "        return classifier_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mvql0FDrwCJT"
   },
   "outputs": [],
   "source": [
    "def normalize_batch(batch):\n",
    "    # normalize using imagenet mean and std\n",
    "    mean = batch.new_tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)\n",
    "    std = batch.new_tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)\n",
    "    batch = batch.div_(255.0)\n",
    "    return (batch - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfurznYswCJW"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])  \n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"/content/gdrive/My Drive/Colab_Notebooks/best-artworks-of-all-time/images\", transform) #FIXME\n",
    "test_dataset = datasets.ImageFolder(\"/content/gdrive/My Drive/Colab_Notebooks/best-artworks-of-all-time/images\", transform) #FIXME\n",
    "\n",
    "# ---------------------- train, test를 split하는 집합 --------------------------\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1* num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler = train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler = test_sampler)\n",
    "print(\"train dataset num:\", len(train_loader))\n",
    "print(\"test dataset num:\",len(test_loader) )\n",
    "\n",
    "\n",
    "def im_convert(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    # denormalize\n",
    "    image = image * np.array([0.5, 0.5, 0.5] + np.array([0.5, 0.5, 0.5]))\n",
    "    image = image.clip(0, 255)\n",
    "    return image\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, classes = dataiter.next()\n",
    "title = [train_dataset.classes[i] for i in classes]\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "for i in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[])\n",
    "    plt.imshow(im_convert(images[i]).astype('uint8'))\n",
    "    ax.set_title(title[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gmz9otAGwCJZ"
   },
   "outputs": [],
   "source": [
    "classifier = ClassifierNet().to(device)\n",
    "autoencoder = AutoencoderNet().to(device)\n",
    "summary(classifier, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4wNtUyuLRj0"
   },
   "outputs": [],
   "source": [
    "#전이학습\n",
    "transfer_learning = True # inference or training first --> False / Transfer learning --> True\n",
    "ckpt_model_path = os.path.join(checkpoint_dir, \"ckpt_epoch__114_batch_id_200.pth\") \n",
    "'''\n",
    "if transfer_learning:\n",
    "    checkpoint = torch.load(ckpt_model_path, map_location=device)\n",
    "    autoencoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "    autoencoder.to(device)\n",
    "\n",
    "pretrained_dict = autoencoder.state_dict()\n",
    "new_model_dict = classifier.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in new_model_dict}\n",
    "new_model_dict.update(pretrained_dict)\n",
    "classifier.load_state_dict(new_model_dict)\n",
    "classifier.train()\n",
    "'''\n",
    "\n",
    "\n",
    "classifier_ckpt_model_path = os.path.join(checkpoint_dir, \"ckpt_epoch_249.pth\") #FIXME\n",
    "if transfer_learning:\n",
    "    checkpoint = torch.load(classifier_ckpt_model_path ,map_location = device)\n",
    "    classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "    classifier.to(device)\n",
    "\n",
    "\n",
    "# Optimizer에는 requires_grad=True 인 parameters들만 들어갈수 있습니다.\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), initial_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9AAZUBswCJf"
   },
   "outputs": [],
   "source": [
    "if running_option == 'training':\n",
    "    if transfer_learning:\n",
    "        transfer_learning_epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        transfer_learning_epoch = 0\n",
    "        \n",
    "    for epoch in range(transfer_learning_epoch, num_epochs):\n",
    "        classifier.train()\n",
    "        running_loss=0.\n",
    "        running_correct=0.\n",
    "        count=0\n",
    "        \n",
    "        for batch_id, (x,labels) in enumerate(train_loader):\n",
    "            n_batch = len(x)\n",
    "            count += n_batch\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # ================= forwar*d =====================\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            x = normalize_batch(x)\n",
    "            outputs = classifier(x)\n",
    "            _,preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # ================= loss =====================\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # =============== Backward ===================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    \n",
    "        mesg = \"{}\\tEpoch {}:\\t[{}/{}]\\tloss: {:.4f}\\tacc: {:.4f}\".format( time.ctime(), epoch + 1, count, \n",
    "                                                                          len(train_dataset),running_loss / len(train_loader),running_correct.float() / len(train_loader))\n",
    "        print(mesg)\n",
    "        running_loss = 0\n",
    "          \n",
    "        classifier.eval().cpu()\n",
    "        ckpt_model_filename = \"ckpt_epoch_\" + str(epoch) + \".pth\"\n",
    "        print(str(epoch), \"th checkpoint is saved!\")\n",
    "        ckpt_model_path = os.path.join(checkpoint_dir, ckpt_model_filename)\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': classifier.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.data\n",
    "        }, ckpt_model_path)\n",
    "\n",
    "        classifier.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4ZtMuc-UYx1"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "classes = train_dataset.classes\n",
    "if running_option == \"test\":\n",
    "  ckpt_model_path = os.path.join(checkpoint_dir, \"ckpt_epoch_264.pth\") #FIXME\n",
    "  checkpoint = torch.load(ckpt_model_path, map_location=device)         \n",
    "  classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "  classifier.to(device)   \n",
    "  class_correct = list(0. for i in range(50))\n",
    "  class_total = list(0. for i in range(50))\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          images, labels = data\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = classifier(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          print(labels, predicted)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          c = (predicted == labels).squeeze()\n",
    "          for i in range(len(labels)):\n",
    "              label = labels[i]\n",
    "              class_correct[label] += c[i].item()\n",
    "              class_total[label] += 1\n",
    "\n",
    "print(len(classes), len(class_correct), len(class_total))\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "for i in range(46):\n",
    "    if(class_total[i] != 0):\n",
    "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZc9_IXNUUVX"
   },
   "source": [
    "https://excelsior-cjh.tistory.com/187 - sparse loss function\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
